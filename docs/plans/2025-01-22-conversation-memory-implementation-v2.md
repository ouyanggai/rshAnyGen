# å¤šè½®å¯¹è¯ä¸é•¿æœŸè®°å¿†ç³»ç»Ÿå®æ–½è®¡åˆ’ (ä¼˜åŒ–ç‰ˆ v2)

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**ç›®æ ‡**: å®ç°åŸºäºä¸»æµæ–¹æ¡ˆçš„å¤šè½®å¯¹è¯ã€é•¿æœŸè®°å¿†å’Œç»Ÿä¸€è®¤è¯ç³»ç»Ÿ
**æŠ€æœ¯æ ˆ**: Redis, Milvus, Keycloak/MaxKey, FastAPI, React
**æ—¶é—´**: 6å‘¨

**ä¼˜åŒ–è¯´æ˜**: æœ¬è®¡åˆ’åŸºäºè¯„å®¡æ–‡æ¡£è¿›è¡Œäº†å…¨é¢ä¼˜åŒ–ï¼Œä¸»è¦æ”¹è¿›åŒ…æ‹¬ï¼š
- Token-aware ä¸‰çº§ä¸Šä¸‹æ–‡ç®¡ç†
- ä¸»é¢˜æ„ŸçŸ¥æ™ºèƒ½æ‘˜è¦ç”Ÿæˆ
- ä¸‰å±‚è®°å¿†æ¶æ„ï¼ˆç”¨æˆ·ç”»åƒ+å®ä½“è®°å¿†+è¯­ä¹‰è®°å¿†ï¼‰
- Keycloak/MaxKey OIDC ç»Ÿä¸€è®¤è¯ï¼ˆå¯¹æ¯”é€‰å‹ä¸­ï¼‰
- è®°å¿†å»é‡ä¸æ—¶é—´è¡°å‡æœºåˆ¶

**è¿›åº¦æ¦‚è§ˆ**: 2025-01-22 æ›´æ–°

| Phase | çŠ¶æ€ | è¯´æ˜ |
|-------|------|------|
| Phase 1: è®¤è¯ç³»ç»Ÿéƒ¨ç½² | âœ… å®Œæˆ | Keycloak å’Œ MaxKey å·²éƒ¨ç½²ï¼Œå¯¹æ¯”é€‰å‹ä¸­ |
| Phase 2: Token-aware ä¸Šä¸‹æ–‡ | ğŸŸ¡ è¿›è¡Œä¸­ | Token è®¡æ•°å™¨å’Œä¸Šä¸‹æ–‡æ„å»ºå™¨å·²åˆ›å»º |
| Phase 3-6: å¾…å®æ–½ | â³ å¾…å¼€å§‹ | æ™ºèƒ½æ‘˜è¦ã€å®ä½“è®°å¿†ã€è¯­ä¹‰è®°å¿†ä¼˜åŒ– |

---

## æœåŠ¡å™¨åŸºç¡€è®¾æ–½

### æœåŠ¡å™¨ä¿¡æ¯

| å±æ€§ | å€¼ |
|------|-----|
| **IP åœ°å€** | 192.168.1.248 |
| **SSH ç”¨æˆ·** | root | å¯†ç  524478201
| **éƒ¨ç½²ç›®å½•** | /root/keycloak, /root/maxkey |
| **æ“ä½œç³»ç»Ÿ** | Ubuntu 22.04.5 LTS |

### æœåŠ¡ç«¯å£åˆ†é…

| æœåŠ¡ | ç«¯å£ | URL | çŠ¶æ€ |
|------|------|-----|------|
| **Keycloak** | 8080 | http://192.168.1.248:8080 | âœ… è¿è¡Œä¸­ |
| **Keycloak Admin** | 8080 | http://192.168.1.248:8080/admin | âœ… å¯è®¿é—® |
| **MaxKey è®¤è¯å‰ç«¯** | 8527 | http://192.168.1.248:8527 | ğŸŸ¡ éƒ¨ç½²ä¸­ |
| **MaxKey ç®¡ç†å‰ç«¯** | 8526 | http://192.168.1.248:8526 | ğŸŸ¡ éƒ¨ç½²ä¸­ |
| **MaxKey è®¤è¯åç«¯** | 9527 | http://192.168.1.248:9527 | ğŸŸ¡ é…ç½®ä¸­ |
| **MaxKey ç®¡ç†åç«¯** | 9526 | http://192.168.1.248:9526 | ğŸŸ¡ é…ç½®ä¸­ |
| **PostgreSQL** | 5432 | å†…éƒ¨ | âœ… è¿è¡Œä¸­ |
| **MySQL** | 3307 | å†…éƒ¨ | ğŸŸ¡ é…ç½®ä¸­ |
| **Redis** | 6379 | 192.168.1.248:6379 | âœ… å¯ç”¨ |

### Docker å®¹å™¨çŠ¶æ€

```bash
# Keycloak å®¹å™¨
keycloak          (quay.io/keycloak/keycloak:23.0)    âœ… Running
keycloak-db       (postgres:15-alpine)                 âœ… Running

# MaxKey å®¹å™¨
maxkey            (maxkeytop/maxkey:latest)            ğŸŸ¡ Restarting
maxkey-mgt        (maxkeytop/maxkey-mgt:latest)        ğŸŸ¡ Restarting
maxkey-frontend   (maxkeytop/maxkey-frontend:latest)   âœ… Running
maxkey-mgt-frontend (maxkeytop/maxkey-mgt-frontend:latest) âœ… Running
maxkey-db         (mysql:8.0.27)                       ğŸŸ¡ Restarting
```

---

## è®¤è¯ç³»ç»Ÿå¯¹æ¯” (Keycloak vs MaxKey)

### éƒ¨ç½²çŠ¶æ€å¯¹æ¯”

| ç‰¹æ€§ | Keycloak | MaxKey |
|------|----------|--------|
| **éƒ¨ç½²çŠ¶æ€** | âœ… å®Œå…¨è¿è¡Œ | ğŸŸ¡ é…ç½®ä¸­ |
| **æ•°æ®åº“** | PostgreSQL | MySQL |
| **ç®¡ç†åå°** | http://192.168.1.248:8080/admin | http://192.168.1.248:8526 |
| **ç®¡ç†è´¦å·** | admin / admin_password | é¦–æ¬¡åˆå§‹åŒ–è®¾ç½® |
| **Realm/App** | rshAnyGen | é»˜è®¤åº”ç”¨ |
| **ä¸­æ–‡æ”¯æŒ** | è‹±æ–‡ä¸ºä¸» | âœ… å›½äº§ä¸­æ–‡ |
| **æ–‡æ¡£** | è‹±æ–‡ | âœ… ä¸­æ–‡ |
| **ç¤¾åŒº** | å›½é™…æ´»è·ƒ | å›½å†…æ´»è·ƒ |

### æŠ€æœ¯å¯¹æ¯”

| é¡¹ç›® | Keycloak | MaxKey |
|------|----------|--------|
| **å¼€æºåè®®** | Apache 2.0 | Apache 2.0 |
| **å¼€å‘å•†** | Red Hat | Dromara (å›½äº§) |
| **åè®®æ”¯æŒ** | OAuth 2.0, OIDC, SAML | OAuth 2.0, OIDC, SAML, CAS |
| **ç•Œé¢è¯­è¨€** | è‹±æ–‡ | ä¸­æ–‡ |
| **å­¦ä¹ æ›²çº¿** | ä¸­ç­‰ | è¾ƒä½ |
| **ä¼ä¸šåŠŸèƒ½** | å…¨é¢ | å…¨é¢ |

### å½“å‰å»ºè®®

**æ¨èä½¿ç”¨ Keycloak** - åŸå› ï¼š
1. éƒ¨ç½²ç¨³å®šï¼Œå·²å®Œå…¨é…ç½®å®Œæˆ
2. å›½é™…æˆç†Ÿæ–¹æ¡ˆï¼Œç¤¾åŒºæ´»è·ƒ
3. åç«¯é›†æˆå·²å®Œæˆï¼ˆJWT ä¸­é—´ä»¶ã€è®¤è¯è·¯ç”±ï¼‰
4. æ–‡æ¡£å®Œå–„ï¼Œæ˜“äºæ‰©å±•

**MaxKey ä½œä¸ºå¤‡é€‰** - ä¼˜åŠ¿ï¼š
1. å›½äº§æ–¹æ¡ˆï¼Œä¸­æ–‡æ–‡æ¡£å‹å¥½
2. æ”¯æŒ CAS åè®®ï¼ˆå¦‚éœ€å…¼å®¹æ—§ç³»ç»Ÿï¼‰
3. ç•Œé¢æœ¬åœ°åŒ–æ›´å¥½

---

## Phase 1: ç»Ÿä¸€è®¤è¯ç³»ç»Ÿ âœ… å·²å®Œæˆ

### Task 1: éƒ¨ç½² Keycloak âœ…

**å®Œæˆæ—¶é—´**: 2025-01-22

**éƒ¨ç½²ä½ç½®**: `192.168.1.248:8080`

**é…ç½®æ–‡ä»¶**:
- `docker-compose.keycloak.yml` - Docker Compose é…ç½®
- `docs/keycloak-config.md` - è¯¦ç»†é…ç½®æ–‡æ¡£

**Realm å’Œ Clients é…ç½®å®Œæˆ**:
- Realm `rshAnyGen` âœ…
- Client `web-ui` (public) âœ…
- Client `backend-api` (confidential) âœ…

**è®¿é—®ä¿¡æ¯**:
```
Keycloak URL: http://192.168.1.248:8080
ç®¡ç†æ§åˆ¶å°: http://192.168.1.248:8080/admin
Realm: rshAnyGen
Admin ç”¨æˆ·å: admin
Admin å¯†ç : admin_password

å‰ç«¯ Client: web-ui (public, ç”¨äº OIDC ç™»å½•)
åç«¯ Client: backend-api
Client Secret: backend-secret-123456
```

**API ç«¯ç‚¹**:
- Token ç«¯ç‚¹: `http://192.168.1.248:8080/realms/rshAnyGen/protocol/openid-connect/token`
- JWKS ç«¯ç‚¹: `http://192.168.1.248:8080/realms/rshAnyGen/protocol/openid-connect/certs`
- ç”¨æˆ·ä¿¡æ¯ç«¯ç‚¹: `http://192.168.1.248:8080/realms/rshAnyGen/protocol/openid-connect/userinfo`

---

### Task 2: åç«¯é›†æˆ Keycloak JWT éªŒè¯ âœ…

**å®Œæˆæ—¶é—´**: 2025-01-22

**å·²åˆ›å»ºæ–‡ä»¶**:
- `apps/gateway/middleware/auth.py` - JWT è®¤è¯ä¸­é—´ä»¶ï¼ŒåŒ…å« JWKS ç¼“å­˜å’Œ token éªŒè¯
- `apps/gateway/routers/auth.py` - è®¤è¯è·¯ç”±ï¼ŒåŒ…å«ç™»å½•/ç™»å‡º/tokenäº¤æ¢ç­‰æ¥å£
- `apps/gateway/config.py` - Keycloak é…ç½®
- `config/default.yaml` - å…±äº« Keycloak é…ç½®

**åŠŸèƒ½å®ç°**:
- âœ… JWT Token éªŒè¯ (RS256)
- âœ… JWKS å…¬é’¥ç¼“å­˜ (è‡ªåŠ¨åˆ·æ–°)
- âœ… è®¤è¯ä¸­é—´ä»¶ (å¯é€‰è·¯å¾„è·³è¿‡)
- âœ… è®¤è¯è·¯ç”± (ç™»å½•ã€ç™»å‡ºã€token äº¤æ¢ã€ç”¨æˆ·ä¿¡æ¯)
- âœ… é…ç½®æ–‡ä»¶é›†æˆ

**ä¾èµ–**:
- `python-jose[cryptography]>=3.3.0` - å·²åœ¨ gateway/requirements.txt

---

### Task 3: å‰ç«¯é›†æˆ Keycloak â³ å¾…å®æ–½

**è®¡åˆ’ä¸­çš„å‰ç«¯é›†æˆ** (æœªå®Œæˆ):
- å®‰è£… `@react-keycloak/web` å’Œ `keycloak-js`
- åˆ›å»º Keycloak é…ç½®å’Œ Provider
- åˆ›å»ºç™»å½•/ç™»å‡ºç»„ä»¶
- é›†æˆåˆ° ChatPage

**è¯´æ˜**: å‰ç«¯é›†æˆå¯ä»¥åç»­è¿›è¡Œï¼Œå½“å‰åç«¯ API å·²å®Œå…¨å¯ç”¨

---

## Phase 2: Token-aware ä¸Šä¸‹æ–‡ç®¡ç† ğŸŸ¡ è¿›è¡Œä¸­

### Task 4: å®ç° Token è®¡æ•°å™¨ âœ…

**å®Œæˆæ—¶é—´**: 2025-01-22

**å·²åˆ›å»ºæ–‡ä»¶**:
- `apps/shared/token_counter.py` - Token è®¡æ•°å™¨ï¼Œæ”¯æŒ tiktoken

**åŠŸèƒ½å®ç°**:
- âœ… æ–‡æœ¬ token è®¡æ•°
- âœ… æ¶ˆæ¯ token è®¡æ•°
- âœ… æ¶ˆæ¯åˆ—è¡¨è£å‰ª (æŒ‰ token é™åˆ¶)
- âœ… æ¨¡å‹ç¼–ç å™¨æ˜ å°„ (qwen-max, gpt-4 ç­‰)

**ä¾èµ–**:
- `tiktoken>=0.5.0` - å·²æ·»åŠ åˆ° orchestrator/requirements.txt

---

### Task 5: å®ç°ä¸‰çº§ä¸Šä¸‹æ–‡æ„å»ºå™¨ âœ…

**å®Œæˆæ—¶é—´**: 2025-01-22

**å·²åˆ›å»ºæ–‡ä»¶**:
- `apps/gateway/services/context_builder.py` - ä¸‰çº§ä¸Šä¸‹æ–‡æ„å»ºå™¨
- `apps/shared/redis_client.py` - Redis æ“ä½œå°è£… (JSON æ”¯æŒ)
- `apps/gateway/services/__init__.py`
- `config/default.yaml` - æ·»åŠ  context é…ç½®

**åŠŸèƒ½å®ç°**:
- âœ… é•¿æœŸè®°å¿†å±‚ (ç”¨æˆ·ç”»åƒ - Redis)
- âœ… çŸ­æœŸæ‘˜è¦å±‚ (ä¼šè¯æ‘˜è¦ - Redis)
- âœ… å·¥ä½œè®°å¿†å±‚ (æœ€è¿‘æ¶ˆæ¯ - Token è£å‰ª)
- âœ… ä¸Šä¸‹æ–‡é…ç½® (working_memory max_tokens: 2048)

**ä¸Šä¸‹æ–‡é¢„ç®—åˆ†é…**:
```
- é•¿æœŸè®°å¿†: ~200 tokens
- çŸ­æœŸæ‘˜è¦: ~500 tokens
- å·¥ä½œè®°å¿†: ~2048 tokens
- å½“å‰æ¶ˆæ¯: ~100 tokens
æ€»è®¡: ~2848 tokens
```

---

### Task 6: é›†æˆä¸Šä¸‹æ–‡æ„å»ºåˆ°èŠå¤©æµç¨‹ â³ éƒ¨åˆ†å®Œæˆ

**è¿›åº¦**: åŸºç¡€æ¶æ„å·²åˆ›å»ºï¼Œå¾…é›†æˆåˆ°å®é™…èŠå¤©æµç¨‹

**å·²åˆ›å»º**:
- `apps/gateway/models.py` - ChatRequest æ·»åŠ  model å­—æ®µ
- `apps/gateway/services/context_builder.py` - ä¸Šä¸‹æ–‡æ„å»ºå™¨

**å¾…å®Œæˆ**:
- åœ¨ `apps/gateway/routers/chat.py` ä¸­é›†æˆ ContextBuilder
- å®ç°æ¶ˆæ¯ä¿å­˜åˆ° Redis
- å®ç° Session æœåŠ¡ (åˆ›å»º/è·å–/è®¾ç½®æ´»è·ƒä¼šè¯)

### Task 1: éƒ¨ç½² Keycloak

**Files:**
- Create: `docker-compose.keycloak.yml`
- Create: `scripts/init_keycloak.sh`

**Step 1: åˆ›å»º Docker Compose é…ç½®**

```yaml
# docker-compose.keycloak.yml
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    container_name: keycloak-db
    environment:
      POSTGRES_DB: keycloak
      POSTGRES_USER: keycloak
      POSTGRES_PASSWORD: keycloak_password
    volumes:
      - keycloak-db:/var/lib/postgresql/data
    networks:
      - keycloak-net

  keycloak:
    image: quay.io/keycloak/keycloak:23.0
    container_name: keycloak
    environment:
      KC_DB: postgres
      KC_DB_URL: jdbc:postgresql://postgres:5432/keycloak
      KC_DB_USERNAME: keycloak
      KC_DB_PASSWORD: keycloak_password
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin_password
      KC_HOSTNAME: 192.168.1.248
      KC_HTTP_ENABLED: true
      KC_PROXY: edge
    ports:
      - "8080:8080"
    depends_on:
      - postgres
    command: start-dev
    networks:
      - keycloak-net

networks:
  keycloak-net:
    driver: bridge

volumes:
  keycloak-db:
```

**Step 2: åˆ›å»ºåˆå§‹åŒ–è„šæœ¬**

```bash
# scripts/init_keycloak.sh
#!/bin/bash

echo "æ­£åœ¨å¯åŠ¨ Keycloak..."
docker-compose -f docker-compose.keycloak.yml up -d

echo "ç­‰å¾… Keycloak å¯åŠ¨(çº¦60ç§’)..."
sleep 60

echo "Keycloak ç®¡ç†æ§åˆ¶å°: http://192.168.1.248:8080/admin"
echo "ç”¨æˆ·å: admin"
echo "å¯†ç : admin_password"
echo ""
echo "è¯·æ‰‹åŠ¨å®Œæˆä»¥ä¸‹é…ç½®:"
echo "1. åˆ›å»º Realm: rshAnyGen"
echo "2. åˆ›å»º Client: web-ui (Public, å¯ç”¨ Standard Flow)"
echo "3. åˆ›å»º Client: backend-api (Confidential, å¯ç”¨ Service Account)"
echo "4. é…ç½® Valid Redirect URIs: http://localhost:9300/*"
echo "5. é…ç½® Web Origins: http://localhost:9300"
```

**Step 3: å¯åŠ¨å¹¶éªŒè¯**

Run: `chmod +x scripts/init_keycloak.sh && ./scripts/init_keycloak.sh`

Expected:
- è®¿é—® http://192.168.1.248:8080/admin
- æˆåŠŸç™»å½•ç®¡ç†æ§åˆ¶å°

**Step 4: æ‰‹åŠ¨é…ç½® Keycloak**

1. åˆ›å»º Realm `rshAnyGen`
2. åˆ›å»º Client `web-ui`:
   - Client Protocol: openid-connect
   - Access Type: public
   - Valid Redirect URIs: `http://localhost:9300/*`
   - Web Origins: `http://localhost:9300`
3. åˆ›å»º Client `backend-api`:
   - Access Type: confidential
   - Service Accounts Enabled: ON
4. åˆ›å»ºæµ‹è¯•ç”¨æˆ·: `test@example.com` / `password123`

**Step 5: Commit**

```bash
git add docker-compose.keycloak.yml scripts/init_keycloak.sh
git commit -m "feat: add keycloak deployment config"
```

---

### Task 2: åç«¯é›†æˆ Keycloak JWT éªŒè¯

**Files:**
- Create: `apps/gateway/middleware/auth.py`
- Modify: `apps/gateway/requirements.txt`
- Modify: `apps/gateway/main.py`
- Update: `config/default.yaml`

**Step 1: æ·»åŠ ä¾èµ–**

```bash
echo "python-jose[cryptography]==3.3.0" >> apps/gateway/requirements.txt
echo "python-keycloak==3.8.0" >> apps/gateway/requirements.txt
pip install -r apps/gateway/requirements.txt
```

**Step 2: åˆ›å»º JWT éªŒè¯ä¸­é—´ä»¶**

```python
# apps/gateway/middleware/auth.py
"""Keycloak JWT è®¤è¯ä¸­é—´ä»¶"""
from fastapi import Request, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from jose import jwt, JWTError
from typing import Optional
import httpx

from apps.shared.config_loader import ConfigLoader
from apps.shared.logger import LogManager

config = ConfigLoader()
logger_manager = LogManager("auth_middleware")
logger = logger_manager.get_logger()

# Keycloak é…ç½®
KEYCLOAK_URL = config.get("keycloak.url", "http://192.168.1.248:8080")
REALM = config.get("keycloak.realm", "rshAnyGen")
CLIENT_ID = config.get("keycloak.client_id", "backend-api")

# JWT é…ç½®
ALGORITHM = "RS256"
PUBLIC_KEY_CACHE = None

security = HTTPBearer()


async def get_keycloak_public_key() -> str:
    """è·å– Keycloak å…¬é’¥"""
    global PUBLIC_KEY_CACHE

    if PUBLIC_KEY_CACHE:
        return PUBLIC_KEY_CACHE

    # ä» Keycloak è·å–å…¬é’¥
    url = f"{KEYCLOAK_URL}/realms/{REALM}"
    async with httpx.AsyncClient() as client:
        response = await client.get(url)
        data = response.json()
        public_key = f"-----BEGIN PUBLIC KEY-----\n{data['public_key']}\n-----END PUBLIC KEY-----"
        PUBLIC_KEY_CACHE = public_key
        return public_key


async def verify_token(token: str) -> dict:
    """éªŒè¯ JWT Token"""
    try:
        public_key = await get_keycloak_public_key()

        # éªŒè¯å¹¶è§£ç  Token
        payload = jwt.decode(
            token,
            public_key,
            algorithms=[ALGORITHM],
            audience=CLIENT_ID
        )

        return payload

    except JWTError as e:
        logger.error(f"JWT validation error: {e}")
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid authentication token"
        )


async def get_current_user(
    credentials: HTTPAuthorizationCredentials = security
) -> dict:
    """ä» Token è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
    token = credentials.credentials
    payload = await verify_token(token)

    return {
        "user_id": payload.get("sub"),
        "email": payload.get("email"),
        "preferred_username": payload.get("preferred_username"),
        "roles": payload.get("realm_access", {}).get("roles", [])
    }


class AuthMiddleware:
    """è®¤è¯ä¸­é—´ä»¶"""

    # æ— éœ€è®¤è¯çš„è·¯å¾„
    EXCLUDED_PATHS = [
        "/docs",
        "/openapi.json",
        "/health"
    ]

    async def __call__(self, request: Request, call_next):
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è®¤è¯
        if any(request.url.path.startswith(path) for path in self.EXCLUDED_PATHS):
            return await call_next(request)

        # è·å– Token
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Bearer "):
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="Missing authentication token"
            )

        token = auth_header.split(" ")[1]

        try:
            # éªŒè¯ Token
            payload = await verify_token(token)

            # å°†ç”¨æˆ·ä¿¡æ¯æ³¨å…¥ request.state
            request.state.user_id = payload.get("sub")
            request.state.email = payload.get("email")
            request.state.username = payload.get("preferred_username")

            logger.info(f"Authenticated user: {request.state.user_id}")

        except HTTPException:
            raise

        return await call_next(request)
```

**Step 3: æ³¨å†Œä¸­é—´ä»¶**

```python
# apps/gateway/main.py
from apps.gateway.middleware.auth import AuthMiddleware

# æ³¨å†Œä¸­é—´ä»¶
app.middleware("http")(AuthMiddleware())
```

**Step 4: æ›´æ–°é…ç½®**

```yaml
# config/default.yaml
# åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ 
keycloak:
  url: "http://192.168.1.248:8080"
  realm: "rshAnyGen"
  client_id: "backend-api"
  client_secret: "YOUR_CLIENT_SECRET"  # ä» Keycloak è·å–
```

**Step 5: åˆ›å»ºæµ‹è¯•**

```python
# tests/gateway/middleware/test_auth.py
import pytest
from fastapi.testclient import TestClient
from apps.gateway.main import app

client = TestClient(app)


def test_missing_token():
    """æµ‹è¯•ç¼ºå°‘ Token"""
    response = client.get("/api/v1/sessions")
    assert response.status_code == 401


def test_invalid_token():
    """æµ‹è¯•æ— æ•ˆ Token"""
    response = client.get(
        "/api/v1/sessions",
        headers={"Authorization": "Bearer invalid_token"}
    )
    assert response.status_code == 401
```

Run: `pytest tests/gateway/middleware/test_auth.py -v`

**Step 6: Commit**

```bash
git add apps/gateway/middleware/auth.py apps/gateway/requirements.txt apps/gateway/main.py config/default.yaml tests/gateway/middleware/test_auth.py
git commit -m "feat: integrate keycloak jwt authentication"
```

---

### Task 3: å‰ç«¯é›†æˆ Keycloak

**Files:**
- Modify: `apps/web-ui/package.json`
- Create: `apps/web-ui/src/keycloak.js`
- Modify: `apps/web-ui/src/main.jsx`
- Create: `apps/web-ui/src/components/auth/KeycloakProvider.jsx`
- Create: `apps/web-ui/src/components/auth/UserMenu.jsx`
- Create: `apps/web-ui/src/api/client.js`

**Step 1: å®‰è£…ä¾èµ–**

```bash
cd apps/web-ui
npm install @react-keycloak/web keycloak-js
```

**Step 2: åˆ›å»º Keycloak é…ç½®**

```javascript
// apps/web-ui/src/keycloak.js
import Keycloak from 'keycloak-js';

const keycloak = new Keycloak({
  url: 'http://192.168.1.248:8080',
  realm: 'rshAnyGen',
  clientId: 'web-ui'
});

export default keycloak;
```

**Step 3: åˆ›å»º Keycloak Provider**

```jsx
// apps/web-ui/src/components/auth/KeycloakProvider.jsx
import { ReactKeycloakProvider } from '@react-keycloak/web';
import keycloak from '../../keycloak';

export default function KeycloakProvider({ children }) {
  const eventLogger = (event, error) => {
    console.log('Keycloak event:', event, error);
  };

  const tokenLogger = (tokens) => {
    console.log('Keycloak tokens updated');
    // å­˜å‚¨ token åˆ° localStorage
    if (tokens.token) {
      localStorage.setItem('kc_token', tokens.token);
      localStorage.setItem('kc_refreshToken', tokens.refreshToken);
    }
  };

  return (
    <ReactKeycloakProvider
      authClient={keycloak}
      onEvent={eventLogger}
      onTokens={tokenLogger}
      initOptions={{
        onLoad: 'check-sso',
        silentCheckSsoRedirectUri: window.location.origin + '/silent-check-sso.html',
        pkceMethod: 'S256'
      }}
    >
      {children}
    </ReactKeycloakProvider>
  );
}
```

**Step 4: æ›´æ–°å…¥å£æ–‡ä»¶**

```jsx
// apps/web-ui/src/main.jsx
import React from 'react';
import ReactDOM from 'react-dom/client';
import App from './App';
import KeycloakProvider from './components/auth/KeycloakProvider';
import './index.css';

ReactDOM.createRoot(document.getElementById('root')).render(
  <React.StrictMode>
    <KeycloakProvider>
      <App />
    </KeycloakProvider>
  </React.StrictMode>
);
```

**Step 5: åˆ›å»º API è¯·æ±‚æ‹¦æˆªå™¨**

```javascript
// apps/web-ui/src/api/client.js
import { useKeycloak } from '@react-keycloak/web';

export const API_BASE_URL = import.meta.env.VITE_API_URL || 'http://localhost:9301';

export function useAuthenticatedFetch() {
  const { keycloak } = useKeycloak();

  const authFetch = async (url, options = {}) => {
    // ç¡®ä¿ token æœ‰æ•ˆ
    await keycloak.updateToken(30);

    const headers = {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${keycloak.token}`,
      ...options.headers
    };

    const response = await fetch(`${API_BASE_URL}${url}`, {
      ...options,
      headers
    });

    if (response.status === 401) {
      // Token è¿‡æœŸ,é‡æ–°ç™»å½•
      keycloak.login();
    }

    return response;
  };

  return authFetch;
}
```

**Step 6: åˆ›å»ºç™»å½•/ç™»å‡ºç»„ä»¶**

```jsx
// apps/web-ui/src/components/auth/UserMenu.jsx
import { useKeycloak } from '@react-keycloak/web';

export default function UserMenu() {
  const { keycloak, initialized } = useKeycloak();

  if (!initialized) {
    return <div className="animate-pulse w-8 h-8 bg-gray-200 rounded-full" />;
  }

  if (!keycloak.authenticated) {
    return (
      <button
        onClick={() => keycloak.login()}
        className="px-4 py-2 bg-primary text-white rounded-lg hover:bg-primary-600"
      >
        ç™»å½•
      </button>
    );
  }

  return (
    <div className="flex items-center gap-2">
      <span className="text-sm font-medium">
        {keycloak.tokenParsed?.preferred_username || 'ç”¨æˆ·'}
      </span>
      <button
        onClick={() => keycloak.logout()}
        className="px-3 py-1 text-sm text-gray-600 hover:text-gray-800"
      >
        ç™»å‡º
      </button>
    </div>
  );
}
```

**Step 7: æ›´æ–° ChatPage é›†æˆè®¤è¯**

```jsx
// apps/web-ui/src/pages/ChatPage.jsx
import { useKeycloak } from '@react-keycloak/web';
import UserMenu from '../components/auth/UserMenu';

export default function ChatPage() {
  const { keycloak, initialized } = useKeycloak();

  // ç­‰å¾…åˆå§‹åŒ–
  if (!initialized) {
    return <div>åŠ è½½ä¸­...</div>;
  }

  // æœªç™»å½•åˆ™æ˜¾ç¤ºç™»å½•æŒ‰é’®
  if (!keycloak.authenticated) {
    return (
      <div className="h-screen flex items-center justify-center">
        <div className="text-center">
          <h1 className="text-2xl font-bold mb-4">æ¬¢è¿ä½¿ç”¨ rshAnyGen</h1>
          <button
            onClick={() => keycloak.login()}
            className="px-6 py-3 bg-primary text-white rounded-lg hover:bg-primary-600"
          >
            ç™»å½•å¼€å§‹ä½¿ç”¨
          </button>
        </div>
      </div>
    );
  }

  // å·²ç™»å½•,æ˜¾ç¤ºèŠå¤©ç•Œé¢
  return (
    <div className="h-screen flex flex-col">
      {/* é¡¶éƒ¨å¯¼èˆª */}
      <div className="flex items-center justify-between px-4 py-3 border-b">
        <h1 className="text-xl font-bold">rshAnyGen</h1>
        <UserMenu />
      </div>

      {/* èŠå¤©å†…å®¹ */}
      {/* ... ç°æœ‰èŠå¤©ç•Œé¢ä»£ç  ... */}
    </div>
  );
}
```

**Step 8: Commit**

```bash
git add apps/web-ui/package.json apps/web-ui/src/keycloak.js apps/web-ui/src/main.jsx apps/web-ui/src/components/auth/ apps/web-ui/src/api/client.js apps/web-ui/src/pages/ChatPage.jsx
git commit -m "feat: integrate keycloak authentication in frontend"
```

---

## Phase 2: Token-aware ä¸Šä¸‹æ–‡ç®¡ç†(Week 2)

### Task 4: å®ç° Token è®¡æ•°å™¨

**Files:**
- Create: `apps/shared/token_counter.py`
- Modify: `apps/gateway/requirements.txt`

**Step 1: æ·»åŠ  tiktoken ä¾èµ–**

```bash
echo "tiktoken==0.5.2" >> apps/gateway/requirements.txt
pip install tiktoken
```

**Step 2: åˆ›å»º Token è®¡æ•°å™¨**

```python
# apps/shared/token_counter.py
"""Token è®¡æ•°å·¥å…·"""
import tiktoken
from typing import List, Dict
from apps.shared.logger import LogManager

logger_manager = LogManager("token_counter")
logger = logger_manager.get_logger()

# æ¨¡å‹å¯¹åº”çš„ç¼–ç å™¨
MODEL_ENCODINGS = {
    "qwen-max": "cl100k_base",
    "qwen-plus": "cl100k_base",
    "gpt-4": "cl100k_base",
    "gpt-3.5-turbo": "cl100k_base"
}


class TokenCounter:
    """Token è®¡æ•°å™¨"""

    def __init__(self, model: str = "qwen-max"):
        encoding_name = MODEL_ENCODINGS.get(model, "cl100k_base")
        self.encoding = tiktoken.get_encoding(encoding_name)
        self.model = model

    def count_text(self, text: str) -> int:
        """è®¡ç®—æ–‡æœ¬çš„ token æ•°"""
        return len(self.encoding.encode(text))

    def count_message(self, message: Dict) -> int:
        """è®¡ç®—å•æ¡æ¶ˆæ¯çš„ token æ•°"""
        role_tokens = self.count_text(message.get("role", ""))
        content_tokens = self.count_text(message.get("content", ""))
        return role_tokens + content_tokens + 4

    def count_messages(self, messages: List[Dict]) -> int:
        """è®¡ç®—æ¶ˆæ¯åˆ—è¡¨çš„æ€» token æ•°"""
        total = sum(self.count_message(msg) for msg in messages)
        return total + 3

    def trim_messages_to_limit(
        self,
        messages: List[Dict],
        max_tokens: int,
        min_messages: int = 1
    ) -> List[Dict]:
        """è£å‰ªæ¶ˆæ¯åˆ—è¡¨ä»¥ç¬¦åˆ token é™åˆ¶"""
        if not messages:
            return []

        # ä»æœ€æ–°æ¶ˆæ¯å¼€å§‹ç´¯åŠ 
        trimmed = []
        current_tokens = 0

        for msg in reversed(messages):
            msg_tokens = self.count_message(msg)

            if current_tokens + msg_tokens > max_tokens:
                if len(trimmed) < min_messages:
                    trimmed.append(msg)
                    current_tokens += msg_tokens
                else:
                    break
            else:
                trimmed.append(msg)
                current_tokens += msg_tokens

        # æ¢å¤åŸå§‹é¡ºåº
        return list(reversed(trimmed))


# å…¨å±€å®ä¾‹
_counter = None

def get_token_counter(model: str = "qwen-max") -> TokenCounter:
    """è·å– Token è®¡æ•°å™¨å•ä¾‹"""
    global _counter
    if _counter is None or _counter.model != model:
        _counter = TokenCounter(model)
    return _counter
```

**Step 3: åˆ›å»ºæµ‹è¯•**

```python
# tests/shared/test_token_counter.py
import pytest
from apps.shared.token_counter import TokenCounter


def test_count_text():
    """æµ‹è¯•æ–‡æœ¬è®¡æ•°"""
    counter = TokenCounter()
    text = "ä½ å¥½ä¸–ç•Œ"
    count = counter.count_text(text)
    assert 4 <= count <= 10


def test_count_message():
    """æµ‹è¯•æ¶ˆæ¯è®¡æ•°"""
    counter = TokenCounter()
    message = {"role": "user", "content": "ä»€ä¹ˆæ˜¯Python?"}
    count = counter.count_message(message)
    assert count > 0


def test_trim_messages():
    """æµ‹è¯•æ¶ˆæ¯è£å‰ª"""
    counter = TokenCounter()
    messages = [
        {"role": "user", "content": "é—®é¢˜1"},
        {"role": "assistant", "content": "å›ç­”1"},
        {"role": "user", "content": "é—®é¢˜2"},
        {"role": "assistant", "content": "å›ç­”2"},
        {"role": "user", "content": "é—®é¢˜3"}
    ]

    trimmed = counter.trim_messages_to_limit(messages, max_tokens=50)
    assert len(trimmed) < len(messages)
    assert trimmed[-1] == messages[-1]
```

Run: `pytest tests/shared/test_token_counter.py -v`

**Step 4: Commit**

```bash
git add apps/shared/token_counter.py tests/shared/test_token_counter.py
git commit -m "feat: add token-aware message counter"
```

---

### Task 5: å®ç°ä¸‰çº§ä¸Šä¸‹æ–‡æ„å»ºå™¨

**Files:**
- Create: `apps/gateway/services/context_builder.py`
- Update: `config/default.yaml`

**Step 1: æ›´æ–°é…ç½®**

```yaml
# config/default.yaml
# æ·»åŠ ä¸Šä¸‹æ–‡é…ç½®
context:
  working_memory:
    max_tokens: 2048
    min_turns: 3
    max_turns: 10

  short_term_summary:
    trigger_tokens: 8192
    max_summary_tokens: 512
    topic_change_threshold: 0.7

  long_term_memory:
    retrieval_top_k: 3
    min_importance: 0.6
    max_age_days: 90
```

**Step 2: åˆ›å»ºä¸Šä¸‹æ–‡æ„å»ºå™¨**

```python
# apps/gateway/services/context_builder.py
"""ä¸‰çº§ä¸Šä¸‹æ–‡æ„å»ºå™¨"""
from typing import List, Dict, Optional
from apps.shared.redis_client import RedisOperations
from apps.shared.token_counter import get_token_counter
from apps.shared.config_loader import ConfigLoader
from apps.shared.logger import LogManager

config = ConfigLoader()
logger_manager = LogManager("context_builder")
logger = logger_manager.get_logger()

# é…ç½®å‚æ•°
WORKING_MEMORY_MAX_TOKENS = config.get("context.working_memory.max_tokens", 2048)
WORKING_MEMORY_MIN_TURNS = config.get("context.working_memory.min_turns", 3)
SUMMARY_MAX_TOKENS = config.get("context.short_term_summary.max_summary_tokens", 512)


class ContextBuilder:
    """ä¸‰çº§ä¸Šä¸‹æ–‡æ„å»ºå™¨"""

    def __init__(self, model: str = "qwen-max"):
        self.redis = RedisOperations()
        self.token_counter = get_token_counter(model)
        self.model = model

    async def build_context(
        self,
        session_id: str,
        user_id: str,
        current_message: str
    ) -> List[Dict]:
        """æ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡

        ä¸‰çº§ç»“æ„:
        1. é•¿æœŸè®°å¿†(ç³»ç»Ÿæç¤º)
        2. çŸ­æœŸæ‘˜è¦(å¦‚æœæœ‰)
        3. å·¥ä½œè®°å¿†(æœ€è¿‘æ¶ˆæ¯)
        4. å½“å‰æ¶ˆæ¯
        """
        await self.redis.init()

        context = []
        total_tokens = 0

        # === ç¬¬ä¸€å±‚: é•¿æœŸè®°å¿† ===
        long_term_memory = await self._build_long_term_memory(user_id, current_message)
        if long_term_memory:
            context.append(long_term_memory)
            total_tokens += self.token_counter.count_message(long_term_memory)

        # === ç¬¬äºŒå±‚: çŸ­æœŸæ‘˜è¦ ===
        summary = await self._get_session_summary(session_id)
        if summary:
            summary_msg = {
                "role": "system",
                "content": f"ã€å¯¹è¯æ‘˜è¦ã€‘\n{summary}"
            }
            context.append(summary_msg)
            total_tokens += self.token_counter.count_message(summary_msg)

        # === ç¬¬ä¸‰å±‚: å·¥ä½œè®°å¿† ===
        working_memory = await self._build_working_memory(session_id)
        if working_memory:
            context.extend(working_memory)
            total_tokens += sum(
                self.token_counter.count_message(msg) for msg in working_memory
            )

        # === ç¬¬å››å±‚: å½“å‰æ¶ˆæ¯ ===
        current_msg = {"role": "user", "content": current_message}
        context.append(current_msg)
        total_tokens += self.token_counter.count_message(current_msg)

        logger.info(
            f"Context built: {len(context)} messages, {total_tokens} tokens "
            f"(working: {len(working_memory)}, summary: {bool(summary)}, "
            f"long_term: {bool(long_term_memory)})"
        )

        return context

    async def _build_long_term_memory(
        self,
        user_id: str,
        current_message: str
    ) -> Optional[Dict]:
        """æ„å»ºé•¿æœŸè®°å¿†ç³»ç»Ÿæç¤º"""
        user_info = await self.redis.client.hgetall(f"user:{user_id}")
        if not user_info:
            return None

        content = f"""ã€ç”¨æˆ·ä¿¡æ¯ã€‘
æ˜µç§°: {user_info.get('nickname', 'ç”¨æˆ·')}
"""

        # æ·»åŠ ç”¨æˆ·æ ‡ç­¾
        tags = await self.redis.client.smembers(f"user:tags:{user_id}")
        if tags:
            content += f"æŠ€èƒ½æ ‡ç­¾: {', '.join(tags)}\n"

        return {
            "role": "system",
            "content": content.strip()
        }

    async def _get_session_summary(self, session_id: str) -> Optional[str]:
        """è·å–ä¼šè¯æ‘˜è¦"""
        summaries = await self.redis.lrange_json(
            f"session:summaries:{session_id}",
            0,
            -1
        )

        if not summaries:
            return None

        # åˆå¹¶æ‰€æœ‰æ‘˜è¦æ®µ
        summary_parts = []
        for item in summaries:
            topic = item.get("topic", "")
            summary = item.get("summary", "")
            summary_parts.append(f"[{topic}] {summary}")

        return "\n".join(summary_parts)

    async def _build_working_memory(self, session_id: str) -> List[Dict]:
        """æ„å»ºå·¥ä½œè®°å¿†"""
        all_messages = await self.redis.lrange_json(
            f"session:messages:{session_id}",
            0,
            -1
        )

        if not all_messages:
            return []

        # ä½¿ç”¨ token counter è£å‰ª
        working_memory = self.token_counter.trim_messages_to_limit(
            all_messages,
            max_tokens=WORKING_MEMORY_MAX_TOKENS,
            min_messages=WORKING_MEMORY_MIN_TURNS * 2
        )

        return working_memory
```

**Step 3: åˆ›å»ºæµ‹è¯•**

```python
# tests/gateway/services/test_context_builder.py
import pytest
from apps.gateway.services.context_builder import ContextBuilder
from apps.gateway.services.message_service import MessageService


@pytest.mark.asyncio
async def test_build_context_empty_session():
    """æµ‹è¯•ç©ºä¼šè¯çš„ä¸Šä¸‹æ–‡æ„å»º"""
    builder = ContextBuilder()

    context = await builder.build_context(
        session_id="test-empty",
        user_id="user-test",
        current_message="ä½ å¥½"
    )

    assert len(context) >= 1
    assert context[-1]["role"] == "user"
    assert context[-1]["content"] == "ä½ å¥½"


@pytest.mark.asyncio
async def test_build_context_with_history():
    """æµ‹è¯•å¸¦å†å²çš„ä¸Šä¸‹æ–‡æ„å»º"""
    builder = ContextBuilder()
    message_service = MessageService()

    # åˆ›å»ºå†å²æ¶ˆæ¯
    session_id = "test-with-history"
    for i in range(5):
        await message_service.save_message(session_id, "user", f"é—®é¢˜{i}")
        await message_service.save_message(session_id, "assistant", f"å›ç­”{i}")

    context = await builder.build_context(
        session_id=session_id,
        user_id="user-test",
        current_message="æ–°é—®é¢˜"
    )

    assert len(context) > 1
    assert context[-1]["content"] == "æ–°é—®é¢˜"


@pytest.mark.asyncio
async def test_token_limit():
    """æµ‹è¯• token é™åˆ¶"""
    builder = ContextBuilder()
    message_service = MessageService()

    # åˆ›å»ºå¤§é‡é•¿æ¶ˆæ¯
    session_id = "test-token-limit"
    long_content = "è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„æ¶ˆæ¯å†…å®¹" * 100
    for i in range(20):
        await message_service.save_message(session_id, "user", long_content)
        await message_service.save_message(session_id, "assistant", long_content)

    context = await builder.build_context(
        session_id=session_id,
        user_id="user-test",
        current_message="æ–°é—®é¢˜"
    )

    # è®¡ç®—æ€» token
    total_tokens = sum(
        builder.token_counter.count_message(msg) for msg in context
    )

    # åº”è¯¥ä¸è¶…è¿‡é™åˆ¶
    assert total_tokens <= 3500  # working(2048) + summary(512) + current(~1000)
```

Run: `pytest tests/gateway/services/test_context_builder.py -v`

**Step 4: Commit**

```bash
git add apps/gateway/services/context_builder.py config/default.yaml tests/gateway/services/test_context_builder.py
git commit -m "feat: implement token-aware three-tier context builder"
```

---

### Task 6: é›†æˆä¸Šä¸‹æ–‡æ„å»ºåˆ°èŠå¤©æµç¨‹

**Files:**
- Modify: `apps/gateway/routers/chat.py`

**Step 1: æ›´æ–°èŠå¤©è·¯ç”±**

```python
# apps/gateway/routers/chat.py
from apps.gateway.services.context_builder import ContextBuilder

@router.post("/stream")
async def chat_stream(request: ChatRequest, req: Request):
    """æµå¼èŠå¤©æ¥å£"""
    user_id = req.state.user_id  # ä» Keycloak JWT è·å–
    session_id = request.session_id

    logger.info(f"Chat request: user={user_id}, session={session_id}")

    # å¤„ç†ä¼šè¯
    session_service = SessionService()
    message_service = MessageService()
    context_builder = ContextBuilder(model=request.model or "qwen-max")

    if not session_id:
        # åˆ›å»ºæ–°ä¼šè¯
        session = await session_service.create_session(user_id)
        session_id = session.session_id
    else:
        # éªŒè¯ä¼šè¯å­˜åœ¨
        session = await session_service.get_session(session_id)
        if not session or session.session.user_id != user_id:
            return StreamingResponse(
                _error_stream("Session not found or access denied"),
                media_type="text/event-stream"
            )

    # è®¾ç½®æ´»è·ƒä¼šè¯
    await session_service.set_active_session(user_id, session_id)

    # æ„å»ºä¸Šä¸‹æ–‡ (ä½¿ç”¨æ–°æ–¹æ³•)
    context_messages = await context_builder.build_context(
        session_id=session_id,
        user_id=user_id,
        current_message=request.message
    )

    async def stream_generator() -> AsyncGenerator[str, None]:
        """ç”Ÿæˆ SSE æµ"""
        full_response = ""
        try:
            orchestrator_request = {
                "session_id": session_id,
                "user_id": user_id,
                "message": request.message,
                "chat_history": context_messages,  # ä½¿ç”¨æ„å»ºçš„ä¸Šä¸‹æ–‡
                "enable_search": request.enable_search,
                "kb_ids": request.kb_ids or [],
            }

            async with httpx.AsyncClient(timeout=30.0) as client:
                async with client.stream(
                    "POST",
                    f"{ORCHESTRATOR_URL}/api/v1/chat",
                    json=orchestrator_request
                ) as response:
                    if response.status_code != 200:
                        error_msg = f"Orchestrator error: {response.status_code}"
                        yield f"data: {json.dumps({'type': 'error', 'message': error_msg})}\n\n"
                        return

                    async for line in response.aiter_lines():
                        if line:
                            yield f"data: {line}\n\n"
                            try:
                                data = json.loads(line)
                                if data.get("type") == "chunk":
                                    full_response += data.get("content", "")
                            except:
                                pass

        except Exception as e:
            logger.error(f"Chat error: {e}")
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"

        finally:
            yield "data: [DONE]\n\n"

            # ä¿å­˜æ¶ˆæ¯
            if full_response:
                await message_service.save_message(session_id, "user", request.message)
                await message_service.save_message(session_id, "assistant", full_response)

    return StreamingResponse(
        stream_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
            "X-Session-Id": session_id
        }
    )
```

**Step 2: Commit**

```bash
git add apps/gateway/routers/chat.py
git commit -m "feat: integrate context builder into chat flow"
```

---

## Phase 3: æ™ºèƒ½æ‘˜è¦ç”Ÿæˆ(Week 3)

### Task 7: ä¸»é¢˜åˆ‡æ¢æ£€æµ‹

**Files:**
- Create: `apps/orchestrator/services/topic_detector.py`

**Step 1: åˆ›å»ºä¸»é¢˜æ£€æµ‹æœåŠ¡**

```python
# apps/orchestrator/services/topic_detector.py
"""ä¸»é¢˜åˆ‡æ¢æ£€æµ‹æœåŠ¡"""
import numpy as np
from typing import List, Dict
from apps.shared.logger import LogManager

logger_manager = LogManager("topic_detector")
logger = logger_manager.get_logger()


class TopicDetector:
    """ä¸»é¢˜åˆ‡æ¢æ£€æµ‹å™¨"""

    def __init__(self, embedding_client, threshold: float = 0.7):
        self.embedding_client = embedding_client
        self.threshold = threshold

    async def detect_topic_change(
        self,
        messages: List[Dict],
        lookback: int = 10
    ) -> bool:
        """æ£€æµ‹ä¸»é¢˜æ˜¯å¦åˆ‡æ¢"""
        # æå–ç”¨æˆ·æ¶ˆæ¯
        user_messages = [
            msg for msg in messages[-lookback:]
            if msg.get("role") == "user"
        ]

        if len(user_messages) < 2:
            return False

        # è·å–æœ€è¿‘ä¸¤æ¡ç”¨æˆ·æ¶ˆæ¯
        recent = user_messages[-2:]

        try:
            # è®¡ç®— embedding
            embeddings = await self.embedding_client.embed_batch([
                msg["content"] for msg in recent
            ])

            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            similarity = self._cosine_similarity(embeddings[0], embeddings[1])

            logger.info(f"Topic similarity: {similarity:.3f} (threshold: {self.threshold})")

            return similarity < self.threshold

        except Exception as e:
            logger.error(f"Topic detection error: {e}")
            return False

    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        v1 = np.array(vec1)
        v2 = np.array(vec2)
        return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))

    async def segment_by_topic(
        self,
        messages: List[Dict],
        min_segment_size: int = 4
    ) -> List[Dict]:
        """æŒ‰ä¸»é¢˜åˆ†æ®µ"""
        if len(messages) < min_segment_size:
            return [{
                "start_idx": 0,
                "end_idx": len(messages) - 1,
                "messages": messages,
                "topic_summary": None
            }]

        segments = []
        current_segment_start = 0

        for i in range(min_segment_size, len(messages)):
            if await self.detect_topic_change(messages[:i+1], lookback=min_segment_size):
                segments.append({
                    "start_idx": current_segment_start,
                    "end_idx": i - 1,
                    "messages": messages[current_segment_start:i],
                    "topic_summary": None
                })
                current_segment_start = i

        # æ·»åŠ æœ€åä¸€æ®µ
        if current_segment_start < len(messages):
            segments.append({
                "start_idx": current_segment_start,
                "end_idx": len(messages) - 1,
                "messages": messages[current_segment_start:],
                "topic_summary": None
            })

        return segments
```

**Step 2: åˆ›å»ºæµ‹è¯•**

```python
# tests/orchestrator/services/test_topic_detector.py
import pytest
from apps.orchestrator.services.topic_detector import TopicDetector


class MockEmbeddingClient:
    """æ¨¡æ‹Ÿ Embedding å®¢æˆ·ç«¯"""

    async def embed_batch(self, texts: list) -> list:
        embeddings = []
        for text in texts:
            if "Python" in text:
                embeddings.append([0.9, 0.1] + [0.0] * 1022)
            elif "Java" in text:
                embeddings.append([0.1, 0.9] + [0.0] * 1022)
            else:
                embeddings.append([0.5, 0.5] + [0.0] * 1022)
        return embeddings


@pytest.mark.asyncio
async def test_detect_topic_change():
    """æµ‹è¯•ä¸»é¢˜åˆ‡æ¢æ£€æµ‹"""
    detector = TopicDetector(MockEmbeddingClient(), threshold=0.7)

    # ç›¸åŒä¸»é¢˜
    messages = [
        {"role": "user", "content": "ä»€ä¹ˆæ˜¯Pythonè£…é¥°å™¨?"},
        {"role": "assistant", "content": "è£…é¥°å™¨æ˜¯..."},
        {"role": "user", "content": "Pythonè£…é¥°å™¨å¦‚ä½•ä½¿ç”¨?"}
    ]

    changed = await detector.detect_topic_change(messages)
    assert changed is False

    # ä¸»é¢˜åˆ‡æ¢
    messages.append({"role": "user", "content": "Javaçš„æ³¨è§£æ˜¯ä»€ä¹ˆ?"})
    changed = await detector.detect_topic_change(messages)
    assert changed is True


@pytest.mark.asyncio
async def test_segment_by_topic():
    """æµ‹è¯•ä¸»é¢˜åˆ†æ®µ"""
    detector = TopicDetector(MockEmbeddingClient(), threshold=0.7)

    messages = [
        {"role": "user", "content": "Pythonè£…é¥°å™¨1"},
        {"role": "assistant", "content": "å›ç­”1"},
        {"role": "user", "content": "Pythonè£…é¥°å™¨2"},
        {"role": "assistant", "content": "å›ç­”2"},
        {"role": "user", "content": "Javaæ³¨è§£1"},
        {"role": "assistant", "content": "å›ç­”3"},
        {"role": "user", "content": "Javaæ³¨è§£2"},
        {"role": "assistant", "content": "å›ç­”4"},
    ]

    segments = await detector.segment_by_topic(messages, min_segment_size=4)
    assert len(segments) >= 1
```

Run: `pytest tests/orchestrator/services/test_topic_detector.py -v`

**Step 3: Commit**

```bash
git add apps/orchestrator/services/topic_detector.py tests/orchestrator/services/test_topic_detector.py
git commit -m "feat: add topic change detection service"
```

---

### Task 8: ä¼˜åŒ–æ‘˜è¦ç”ŸæˆæœåŠ¡

**Files:**
- Modify: `apps/orchestrator/services/summary_generator.py`

**Step 1: é‡æ„æ‘˜è¦ç”Ÿæˆå™¨**

```python
# apps/orchestrator/services/summary_generator.py
"""ä¼šè¯æ‘˜è¦ç”ŸæˆæœåŠ¡(ä¼˜åŒ–ç‰ˆ)"""
from typing import List, Dict
from datetime import datetime
from apps.orchestrator.services.topic_detector import TopicDetector
from apps.shared.redis_client import RedisOperations
from apps.shared.config_loader import ConfigLoader
from apps.shared.logger import LogManager

config = ConfigLoader()
logger_manager = LogManager("summary_generator")
logger = logger_manager.get_logger()


class SummaryGenerator:
    """æ‘˜è¦ç”Ÿæˆå™¨"""

    def __init__(self, llm_client, embedding_client):
        self.llm_client = llm_client
        self.embedding_client = embedding_client
        self.topic_detector = TopicDetector(embedding_client)
        self.redis = RedisOperations()

    async def generate_summary(self, session_id: str) -> List[Dict]:
        """ç”Ÿæˆä¼šè¯åˆ†æ®µæ‘˜è¦"""
        await self.redis.init()

        # è·å–æ‰€æœ‰æ¶ˆæ¯
        all_messages = await self.redis.lrange_json(
            f"session:messages:{session_id}",
            0,
            -1
        )

        if len(all_messages) < 4:
            return []

        # æŒ‰ä¸»é¢˜åˆ†æ®µ
        segments = await self.topic_detector.segment_by_topic(all_messages)

        logger.info(f"Segmented session {session_id} into {len(segments)} topics")

        # ä¸ºæ¯æ®µç”Ÿæˆæ‘˜è¦
        summaries = []
        for segment in segments:
            summary = await self._summarize_segment(segment["messages"])

            segment_summary = {
                "topic": summary.get("topic", "æœªçŸ¥ä¸»é¢˜"),
                "summary": summary.get("summary", ""),
                "message_range": [segment["start_idx"], segment["end_idx"]],
                "created_at": datetime.now().isoformat()
            }
            summaries.append(segment_summary)

        # ä¿å­˜åˆ†æ®µæ‘˜è¦
        await self.redis.client.delete(f"session:summaries:{session_id}")
        for summary in summaries:
            await self.redis.rpush_json(f"session:summaries:{session_id}", summary)

        logger.info(f"Generated {len(summaries)} summaries for session {session_id}")
        return summaries

    async def _summarize_segment(self, messages: List[Dict]) -> Dict:
        """ä¸ºå•ä¸ªä¸»é¢˜æ®µç”Ÿæˆæ‘˜è¦"""
        # æ ¼å¼åŒ–æ¶ˆæ¯
        formatted = []
        for msg in messages:
            role = "ç”¨æˆ·" if msg["role"] == "user" else "AI"
            formatted.append(f"{role}: {msg['content']}")

        conversation = "\n".join(formatted)

        prompt = f"""è¯·ä¸ºä»¥ä¸‹å¯¹è¯ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ã€‚

å¯¹è¯å†…å®¹:
{conversation}

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡º(åªè¾“å‡ºJSON,ä¸è¦å…¶ä»–å†…å®¹):
{{
  "topic": "ç”¨3-5ä¸ªå­—æ¦‚æ‹¬ä¸»é¢˜",
  "summary": "ç”¨1-2å¥è¯æ€»ç»“å…³é”®ä¿¡æ¯,ä¿ç•™é‡è¦å†³ç­–å’Œç»“è®º"
}}
"""

        try:
            response = await self.llm_client.complete(
                prompt,
                max_tokens=200,
                temperature=0.3,
                response_format="json"
            )

            import json
            result = json.loads(response)
            return result

        except Exception as e:
            logger.error(f"Segment summarization error: {e}")
            return {
                "topic": "å¯¹è¯ç‰‡æ®µ",
                "summary": "æ‘˜è¦ç”Ÿæˆå¤±è´¥"
            }
```

**Step 2: Commit**

```bash
git add apps/orchestrator/services/summary_generator.py
git commit -m "feat: optimize summary generation with topic segmentation"
```

---

## Phase 4: å®ä½“è®°å¿†å±‚(Week 4)

### Task 9: å®ä½“æå–æœåŠ¡

**Files:**
- Create: `apps/orchestrator/models/entity.py`
- Create: `apps/orchestrator/services/entity_extractor.py`

**Step 1: å®šä¹‰å®ä½“æ¨¡å‹**

```python
# apps/orchestrator/models/entity.py
"""å®ä½“ç›¸å…³æ¨¡å‹"""
from pydantic import BaseModel, Field
from typing import Optional, Dict, Literal


class Entity(BaseModel):
    """å®ä½“"""
    entity_id: Optional[str] = None
    type: Literal["person", "project", "event", "location", "concept"]
    name: str = Field(..., min_length=1, max_length=100)
    attributes: Dict = Field(default_factory=dict)
    confidence: float = Field(default=1.0, ge=0, le=1)


class EntityExtraction(BaseModel):
    """å®ä½“æå–ç»“æœ"""
    entities: list[Entity]
```

**Step 2: åˆ›å»ºå®ä½“æå–å™¨**

```python
# apps/orchestrator/services/entity_extractor.py
"""å®ä½“æå–æœåŠ¡"""
import re
import uuid
from typing import List, Dict
from datetime import datetime

from apps.orchestrator.models.entity import Entity, EntityExtraction
from apps.shared.redis_client import RedisOperations
from apps.shared.logger import LogManager

logger_manager = LogManager("entity_extractor")
logger = logger_manager.get_logger()

# å®ä½“æå–è§„åˆ™
ENTITY_PATTERNS = {
    "person": [
        r"(?:æˆ‘|ä»–|å¥¹|ä»–ä»¬)(?:æ˜¯|å«|åå­—æ˜¯|å«åš)\s*([^\s,ï¼Œã€‚.!?!\n]{2,10})",
        r"(?:åŒäº‹|æœ‹å‹|è€å¸ˆ|é¢†å¯¼|ç»ç†)\s*([^\s,ï¼Œã€‚.!?!\n]{2,10})",
    ],
    "project": [
        r"(?:é¡¹ç›®|ç³»ç»Ÿ|äº§å“|åº”ç”¨|å¹³å°)(?:å«|åä¸º|æ˜¯|å«åš)\s*([^\s,ï¼Œã€‚.!?!\n]{2,20})",
    ],
    "location": [
        r"(?:åœ¨|ä½äº|ä»|å»|åˆ°)\s*((?:åŒ—äº¬|ä¸Šæµ·|å¹¿å·|æ·±åœ³|æ­å·|æˆéƒ½)\w{0,6})",
    ],
    "date": [
        r"\d{4}[-å¹´]\d{1,2}[-æœˆ]\d{1,2}[æ—¥å·]?",
    ],
}


class EntityExtractor:
    """å®ä½“æå–å™¨(è§„åˆ™ + LLM æ··åˆ)"""

    def __init__(self, llm_client=None):
        self.llm_client = llm_client
        self.redis = RedisOperations()

    async def extract_entities(
        self,
        user_message: str,
        ai_response: str,
        user_id: str,
        session_id: str
    ) -> List[Entity]:
        """æå–å¯¹è¯ä¸­çš„å®ä½“"""
        entities = []

        # è§„åˆ™æå–
        rule_entities = self._extract_by_rules(user_message)
        entities.extend(rule_entities)

        # LLM è¡¥å……(å¯é€‰)
        if self.llm_client and self._should_use_llm(user_message):
            llm_entities = await self._extract_by_llm(user_message, ai_response)
            entities.extend(llm_entities)

        # å»é‡åˆå¹¶
        entities = self._deduplicate_entities(entities)

        # ä¿å­˜åˆ° Redis
        for entity in entities:
            await self._save_entity(entity, user_id, session_id)

        logger.info(f"Extracted {len(entities)} entities from conversation")
        return entities

    def _extract_by_rules(self, text: str) -> List[Entity]:
        """åŸºäºè§„åˆ™æå–å®ä½“"""
        entities = []

        for entity_type, patterns in ENTITY_PATTERNS.items():
            for pattern in patterns:
                matches = re.findall(pattern, text)
                for match in matches:
                    entities.append(Entity(
                        type=entity_type,
                        name=match.strip(),
                        confidence=0.8
                    ))

        return entities

    def _should_use_llm(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ç”¨ LLM æå–"""
        keywords = ["æ˜¯", "å«", "é¡¹ç›®", "ç³»ç»Ÿ", "åå­—", "å…¬å¸", "å›¢é˜Ÿ"]
        return any(kw in text for kw in keywords)

    async def _extract_by_llm(
        self,
        user_message: str,
        ai_response: str
    ) -> List[Entity]:
        """ä½¿ç”¨ LLM æå–å®ä½“"""
        conversation = f"ç”¨æˆ·: {user_message}\nAI: {ai_response}"

        prompt = f"""ä»ä»¥ä¸‹å¯¹è¯ä¸­æå–å…³é”®å®ä½“ã€‚

{conversation}

è¯·æå–ä»¥ä¸‹ç±»å‹çš„å®ä½“:
- person: äººå
- project: é¡¹ç›®/ç³»ç»Ÿ/äº§å“åç§°
- location: åœ°ç‚¹
- concept: é‡è¦æ¦‚å¿µ/æŠ€æœ¯

åªè¾“å‡ºJSONæ ¼å¼(ä¸è¦å…¶ä»–å†…å®¹):
{{
  "entities": [
    {{
      "type": "person|project|location|concept",
      "name": "å®ä½“åç§°",
      "attributes": {{"role": "è§’è‰²"}},
      "confidence": 0.9
    }}
  ]
}}

å¦‚æœæ²¡æœ‰å®ä½“,è¿”å›ç©ºæ•°ç»„ã€‚"""

        try:
            response = await self.llm_client.complete(
                prompt,
                max_tokens=300,
                temperature=0.2
            )

            import json
            result = json.loads(response)
            extraction = EntityExtraction(**result)
            return extraction.entities

        except Exception as e:
            logger.error(f"LLM entity extraction error: {e}")
            return []

    def _deduplicate_entities(self, entities: List[Entity]) -> List[Entity]:
        """å»é‡å®ä½“"""
        seen = {}
        for entity in entities:
            key = f"{entity.type}:{entity.name.lower()}"
            if key not in seen or entity.confidence > seen[key].confidence:
                seen[key] = entity
        return list(seen.values())

    async def _save_entity(
        self,
        entity: Entity,
        user_id: str,
        session_id: str
    ):
        """ä¿å­˜å®ä½“åˆ° Redis"""
        await self.redis.init()

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        existing_id = await self._find_existing_entity(entity, user_id)

        if existing_id:
            # æ›´æ–°ç°æœ‰å®ä½“
            await self.redis.client.hincrby(
                f"entity:{existing_id}",
                "mention_count",
                1
            )
            await self.redis.client.hset(
                f"entity:{existing_id}",
                "last_mentioned",
                datetime.now().isoformat()
            )
        else:
            # åˆ›å»ºæ–°å®ä½“
            entity_id = f"entity-{entity.type}-{uuid.uuid4().hex[:8]}"
            entity_data = {
                "type": entity.type,
                "name": entity.name,
                "attributes": entity.attributes,
                "first_mentioned": datetime.now().isoformat(),
                "last_mentioned": datetime.now().isoformat(),
                "mention_count": 1,
                "confidence": entity.confidence,
                "session_id": session_id
            }

            await self.redis.client.hset(f"entity:{entity_id}", mapping=entity_data)
            await self.redis.client.zadd(
                f"user:entities:{entity.type}:{user_id}",
                {entity_id: int(datetime.now().timestamp())}
            )

    async def _find_existing_entity(
        self,
        entity: Entity,
        user_id: str
    ) -> Optional[str]:
        """æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨ç›¸åŒå®ä½“"""
        await self.redis.init()

        entity_ids = await self.redis.client.zrevrange(
            f"user:entities:{entity.type}:{user_id}",
            0,
            -1
        )

        for entity_id in entity_ids:
            data = await self.redis.client.hgetall(f"entity:{entity_id}")
            if data and data.get("name", "").lower() == entity.name.lower():
                return entity_id

        return None

    async def get_user_entities(
        self,
        user_id: str,
        entity_type: Optional[str] = None,
        limit: int = 50
    ) -> List[Dict]:
        """è·å–ç”¨æˆ·çš„å®ä½“åˆ—è¡¨"""
        await self.redis.init()

        if entity_type:
            entity_ids = await self.redis.client.zrevrange(
                f"user:entities:{entity_type}:{user_id}",
                0,
                limit - 1
            )
        else:
            entity_ids = []
            for etype in ["person", "project", "location", "concept"]:
                ids = await self.redis.client.zrevrange(
                    f"user:entities:{etype}:{user_id}",
                    0,
                    limit - 1
                )
                entity_ids.extend(ids)

        entities = []
        for entity_id in entity_ids[:limit]:
            data = await self.redis.client.hgetall(f"entity:{entity_id}")
            if data:
                data["entity_id"] = entity_id
                entities.append(data)

        return entities
```

**Step 3: åˆ›å»ºæµ‹è¯•**

```python
# tests/orchestrator/services/test_entity_extractor.py
import pytest
from apps.orchestrator.services.entity_extractor import EntityExtractor


def test_extract_by_rules():
    """æµ‹è¯•è§„åˆ™æå–"""
    extractor = EntityExtractor()

    text = "æˆ‘å«å¼ ä¸‰,åœ¨åŒ—äº¬å·¥ä½œ,è´Ÿè´£rshAnyGené¡¹ç›®"
    entities = extractor._extract_by_rules(text)

    assert len(entities) >= 2


@pytest.mark.asyncio
async def test_save_and_retrieve_entities():
    """æµ‹è¯•ä¿å­˜å’Œæ£€ç´¢å®ä½“"""
    extractor = EntityExtractor()

    from apps.orchestrator.models.entity import Entity

    entity = Entity(
        type="person",
        name="æå››",
        attributes={"role": "åŒäº‹"},
        confidence=0.9
    )

    await extractor._save_entity(entity, "user-test", "session-test")
    await extractor._save_entity(entity, "user-test", "session-test")

    entities = await extractor.get_user_entities("user-test", "person")

    assert len(entities) >= 1
    assert entities[0]["name"] == "æå››"
    assert int(entities[0]["mention_count"]) == 2
```

Run: `pytest tests/orchestrator/services/test_entity_extractor.py -v`

**Step 4: Commit**

```bash
git add apps/orchestrator/services/entity_extractor.py apps/orchestrator/models/entity.py tests/orchestrator/services/test_entity_extractor.py
git commit -m "feat: add entity extraction service with rule-based and llm hybrid approach"
```

---

## Phase 5: è¯­ä¹‰è®°å¿†ä¼˜åŒ–(Week 5)

### Task 10: è®°å¿†å»é‡æœåŠ¡

**Files:**
- Modify: `apps/orchestrator/services/memory_service.py`

**Step 1: æ·»åŠ å»é‡åŠŸèƒ½**

```python
# apps/orchestrator/services/memory_service.py
# åœ¨ MemoryService ç±»ä¸­æ·»åŠ æ–¹æ³•

async def deduplicate_memory(
    self,
    new_content: str,
    user_id: str,
    new_embedding: List[float]
) -> Optional[int]:
    """æ£€æŸ¥è®°å¿†æ˜¯å¦é‡å¤

    Returns:
        å¦‚æœé‡å¤,è¿”å›å·²å­˜åœ¨çš„è®°å¿† ID;å¦åˆ™è¿”å› None
    """
    # æ£€ç´¢ç›¸ä¼¼è®°å¿†(æœ€è¿‘30å¤©)
    thirty_days_ago = int(time.time()) - (30 * 24 * 3600)

    results = self.collection.search(
        data=[new_embedding],
        anns_field="vector",
        param={"metric_type": "COSINE", "params": {"ef": 32}},
        limit=5,
        expr=f"user_id == '{user_id}' and created_at >= {thirty_days_ago}",
        output_fields=["id", "content", "importance", "access_count"]
    )

    if not results or not results[0]:
        return None

    for hit in results[0]:
        similarity = 1 - hit.distance

        # é«˜ç›¸ä¼¼åº¦(>0.92) = å‡ ä¹ç›¸åŒ
        if similarity > 0.92:
            logger.info(
                f"Found duplicate memory: {hit.id} "
                f"(similarity: {similarity:.3f})"
            )
            await self._update_memory_access(hit.id)
            return hit.id

        # ä¸­ç­‰ç›¸ä¼¼åº¦(0.80-0.92) = éœ€è¦åˆå¹¶
        elif similarity > 0.80:
            logger.info(
                f"Found similar memory: {hit.id} "
                f"(similarity: {similarity:.3f}), merging..."
            )
            merged_content = await self._merge_memories(
                new_content,
                hit.entity.get("content")
            )
            await self._update_memory_content(hit.id, merged_content)
            return hit.id

    return None


async def save_memory_with_dedup(
    self,
    user_id: str,
    memory: MemoryItem,
    session_id: str,
    embedding: List[float]
):
    """ä¿å­˜è®°å¿†(å¸¦å»é‡)"""

    # æ£€æŸ¥é‡å¤
    existing_id = await self.deduplicate_memory(
        memory.content,
        user_id,
        embedding
    )

    if existing_id:
        logger.info(f"Memory deduplicated, using existing: {existing_id}")
        return

    # ä¿å­˜æ–°è®°å¿†
    await self.save_memory(user_id, memory, session_id, embedding)
```

**Step 2: Commit**

```bash
git add apps/orchestrator/services/memory_service.py
git commit -m "feat: add memory deduplication with semantic similarity"
```

---

### Task 11: æ—¶é—´è¡°å‡æœºåˆ¶

**Files:**
- Create: `apps/orchestrator/services/memory_scorer.py`
- Modify: `apps/orchestrator/services/background_tasks.py`

**Step 1: åˆ›å»ºè®°å¿†è¯„åˆ†å™¨**

```python
# apps/orchestrator/services/memory_scorer.py
"""è®°å¿†é‡è¦æ€§è¯„åˆ†å™¨"""
import math
from datetime import datetime
from typing import Dict

from apps.shared.logger import LogManager

logger_manager = LogManager("memory_scorer")
logger = logger_manager.get_logger()


class MemoryScorer:
    """è®°å¿†è¯„åˆ†å™¨(è®¡ç®—æ—¶é—´è¡°å‡åçš„é‡è¦æ€§)"""

    def __init__(self, half_life_days: int = 30):
        self.half_life_days = half_life_days

    def calculate_current_importance(
        self,
        base_importance: float,
        created_at: datetime,
        access_count: int = 0,
        last_accessed: datetime = None
    ) -> float:
        """è®¡ç®—è®°å¿†çš„å½“å‰é‡è¦æ€§

        å…¬å¼:
        current_importance = base_importance * time_decay + access_boost
        """
        # æ—¶é—´è¡°å‡(æŒ‡æ•°è¡°å‡)
        days_old = (datetime.now() - created_at).days
        time_decay = math.exp(-days_old / self.half_life_days)

        # è®¿é—®é¢‘ç‡åŠ æˆ(æœ€å¤š+0.3)
        access_boost = min(access_count * 0.05, 0.3)

        # æœ€è¿‘è®¿é—®åŠ æˆ
        recent_access_boost = 0
        if last_accessed:
            days_since_access = (datetime.now() - last_accessed).days
            if days_since_access < 7:
                recent_access_boost = 0.2 * (1 - days_since_access / 7)

        # æœ€ç»ˆåˆ†æ•°
        final_score = min(
            base_importance * time_decay + access_boost + recent_access_boost,
            1.0
        )

        return final_score

    def should_archive(
        self,
        current_importance: float,
        threshold: float = 0.1
    ) -> bool:
        """åˆ¤æ–­è®°å¿†æ˜¯å¦åº”è¯¥å½’æ¡£"""
        return current_importance < threshold
```

**Step 2: æ·»åŠ å®šæ—¶ä»»åŠ¡**

```python
# apps/orchestrator/services/background_tasks.py
# æ·»åŠ è®°å¿†è¡°å‡å¤„ç†ä»»åŠ¡

async def _process_memory_decay(self):
    """å¤„ç†è®°å¿†æ—¶é—´è¡°å‡"""
    from apps.orchestrator.services.memory_scorer import update_memory_scores
    from apps.orchestrator.services.memory_service import MemoryService

    memory_service = MemoryService()

    while self.running:
        try:
            await self.redis.init()

            # è·å–æ‰€æœ‰ç”¨æˆ·
            user_keys = await self.redis.client.keys("user:*")
            user_ids = [key.split(":")[1] for key in user_keys if key.startswith("user:") and key.count(":") == 1]

            for user_id in user_ids:
                await update_memory_scores(memory_service, user_id)

            # æ¯å¤©æ‰§è¡Œä¸€æ¬¡
            await asyncio.sleep(24 * 3600)

        except Exception as e:
            logger.error(f"Memory decay processing error: {e}")
            await asyncio.sleep(3600)

# åœ¨ start æ–¹æ³•ä¸­æ·»åŠ 
async def start(self):
    self.running = True
    logger.info("Background task processor started")

    await asyncio.gather(
        self._process_summaries(),
        self._process_memory_extractions(),
        self._process_memory_decay(),  # æ–°å¢
    )
```

**Step 3: Commit**

```bash
git add apps/orchestrator/services/memory_scorer.py apps/orchestrator/services/background_tasks.py
git commit -m "feat: add memory importance scoring with time decay"
```

---

## Phase 6: æœ€ç»ˆé›†æˆä¸æµ‹è¯•(Week 6)

### Task 12: ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•

**Files:**
- Create: `tests/integration/test_complete_flow.py`

**Step 1: åˆ›å»ºå®Œæ•´æµç¨‹æµ‹è¯•**

```python
# tests/integration/test_complete_flow.py
"""å®Œæ•´æµç¨‹é›†æˆæµ‹è¯•"""
import pytest
import asyncio
from httpx import AsyncClient


@pytest.mark.asyncio
async def test_complete_conversation_with_memory():
    """æµ‹è¯•å¸¦è®°å¿†çš„å®Œæ•´å¯¹è¯æµç¨‹"""

    # æ¨¡æ‹Ÿ Keycloak token
    token = "mock_jwt_token"

    async with AsyncClient(base_url="http://localhost:9301") as client:
        headers = {"Authorization": f"Bearer {token}"}

        # 1. åˆ›å»ºä¼šè¯
        response = await client.post(
            "/api/v1/sessions",
            json={"user_id": "test-user", "title": "æµ‹è¯•ä¼šè¯"},
            headers=headers
        )
        assert response.status_code == 200
        session_id = response.json()["session_id"]

        # 2. å‘é€ç¬¬ä¸€æ¡æ¶ˆæ¯(å»ºç«‹ä¸Šä¸‹æ–‡)
        response = await client.post(
            "/api/v1/chat/stream",
            json={
                "message": "æˆ‘å«å¼ ä¸‰,æ˜¯ä¸€åPythonå¼€å‘å·¥ç¨‹å¸ˆ",
                "session_id": session_id
            },
            headers=headers
        )
        assert response.status_code == 200

        # ç­‰å¾…æ¶ˆæ¯ä¿å­˜å’Œå®ä½“æå–
        await asyncio.sleep(2)

        # 3. å‘é€ç¬¬äºŒæ¡æ¶ˆæ¯(æµ‹è¯•å®ä½“è®°å¿†)
        response = await client.post(
            "/api/v1/chat/stream",
            json={
                "message": "æˆ‘æ“…é•¿ä»€ä¹ˆ?",
                "session_id": session_id
            },
            headers=headers
        )
        # æœŸæœ›: AI èƒ½è®°ä½"Pythonå¼€å‘"

        # 4. åˆ‡æ¢ä¸»é¢˜è§¦å‘æ‘˜è¦
        for i in range(5):
            await client.post(
                "/api/v1/chat/stream",
                json={
                    "message": f"Pythoné—®é¢˜{i}",
                    "session_id": session_id
                },
                headers=headers
            )

        # ç­‰å¾…æ‘˜è¦ç”Ÿæˆ
        await asyncio.sleep(5)

        # 5. éªŒè¯æ‘˜è¦å­˜åœ¨
        response = await client.get(
            f"/api/v1/sessions/{session_id}",
            headers=headers
        )
        session_detail = response.json()

        # 6. åˆ›å»ºæ–°ä¼šè¯æµ‹è¯•è·¨ä¼šè¯è®°å¿†
        response = await client.post(
            "/api/v1/sessions",
            json={"user_id": "test-user", "title": "æ–°ä¼šè¯"},
            headers=headers
        )
        new_session_id = response.json()["session_id"]

        response = await client.post(
            "/api/v1/chat/stream",
            json={
                "message": "ä½ è¿˜è®°å¾—æˆ‘å«ä»€ä¹ˆåå­—å—?",
                "session_id": new_session_id
            },
            headers=headers
        )
        # æœŸæœ›: AI èƒ½ä»é•¿æœŸè®°å¿†ä¸­å¬å›"å¼ ä¸‰"
```

**Step 2: æ€§èƒ½æµ‹è¯•**

```python
# tests/performance/test_context_performance.py
import pytest
import time
from apps.gateway.services.context_builder import ContextBuilder


@pytest.mark.asyncio
async def test_context_build_performance():
    """æµ‹è¯•ä¸Šä¸‹æ–‡æ„å»ºæ€§èƒ½"""
    builder = ContextBuilder()

    # å‡†å¤‡æµ‹è¯•æ•°æ®(100æ¡æ¶ˆæ¯)
    session_id = "perf-test-session"
    # ... åˆ›å»º100æ¡æ¶ˆæ¯ ...

    # æµ‹è¯•æ€§èƒ½
    start = time.time()

    for i in range(10):
        context = await builder.build_context(
            session_id=session_id,
            user_id="perf-user",
            current_message="æµ‹è¯•æ¶ˆæ¯"
        )

    elapsed = time.time() - start
    avg_time = elapsed / 10

    print(f"Average context build time: {avg_time*1000:.2f}ms")

    # è¦æ±‚å¹³å‡æ—¶é—´ < 100ms
    assert avg_time < 0.1
```

**Step 3: Commit**

```bash
git add tests/integration/test_complete_flow.py tests/performance/test_context_performance.py
git commit -m "test: add end-to-end and performance tests"
```

---

### Task 13: æ–‡æ¡£å’Œéƒ¨ç½²

**Files:**
- Create: `docs/ARCHITECTURE.md`
- Update: `README.md`

**Step 1: åˆ›å»ºæ¶æ„æ–‡æ¡£**

```markdown
# docs/ARCHITECTURE.md

# ç³»ç»Ÿæ¶æ„æ–‡æ¡£

## æ•´ä½“æ¶æ„

ç³»ç»Ÿé‡‡ç”¨ä¸‰å±‚æ¶æ„:
- **å‰ç«¯å±‚**: React + Keycloakè®¤è¯
- **ç½‘å…³å±‚**: FastAPI + JWTéªŒè¯ + Token-awareä¸Šä¸‹æ–‡ç®¡ç†
- **ç¼–æ’å±‚**: LangGraph + å¤šæœåŠ¡é›†æˆ

## æ ¸å¿ƒä¼˜åŒ–

### Token-aware ä¸‰çº§ä¸Šä¸‹æ–‡ç®¡ç†
1. å·¥ä½œè®°å¿†: æœ€è¿‘3-5è½®å¯¹è¯,çº¦2K tokens
2. çŸ­æœŸè®°å¿†: ä¸»é¢˜æ„ŸçŸ¥æ‘˜è¦,çº¦500 tokens
3. é•¿æœŸè®°å¿†: è¯­ä¹‰æ£€ç´¢ç›¸å…³è®°å¿†,çº¦1K tokens

### ä¸‰å±‚è®°å¿†æ¶æ„
1. ç”¨æˆ·ç”»åƒå±‚: Redis Hashå­˜å‚¨åŸºç¡€ä¿¡æ¯
2. å®ä½“è®°å¿†å±‚: Redis + è§„åˆ™æå–ç»“æ„åŒ–ä¿¡æ¯
3. è¯­ä¹‰è®°å¿†å±‚: Milvuså‘é‡å­˜å‚¨ + å»é‡ + æ—¶é—´è¡°å‡

### Keycloak OIDCè®¤è¯
- JWT TokenéªŒè¯
- SSOæ”¯æŒ
- å¤šç³»ç»Ÿé›†æˆèƒ½åŠ›

## æ€§èƒ½æŒ‡æ ‡

- ä¸Šä¸‹æ–‡æ„å»ºå»¶è¿Ÿ: P95 < 100ms
- è®°å¿†æ£€ç´¢å»¶è¿Ÿ: P95 < 200ms
- TokenèŠ‚çœ: 40-60%
```

**Step 2: æ›´æ–° README**

```markdown
# README.md æ›´æ–°å†…å®¹

## æ–°å¢åŠŸèƒ½

### Keycloak ç»Ÿä¸€è®¤è¯
- OIDC æ ‡å‡†åè®®
- JWT Token éªŒè¯
- SSO æ”¯æŒ

### Token-aware ä¸Šä¸‹æ–‡ç®¡ç†
- ä¸‰çº§ç¼“å­˜æ¶æ„
- åŠ¨æ€ Token è£å‰ª
- ä¸»é¢˜æ„ŸçŸ¥æ‘˜è¦

### ä¸‰å±‚è®°å¿†ç³»ç»Ÿ
- ç”¨æˆ·ç”»åƒ + å®ä½“è®°å¿† + è¯­ä¹‰è®°å¿†
- æ™ºèƒ½å»é‡
- æ—¶é—´è¡°å‡æœºåˆ¶

### å®ä½“æå–
- è§„åˆ™ + LLM æ··åˆæå–
- äººåã€é¡¹ç›®ã€åœ°ç‚¹ç­‰ç»“æ„åŒ–ä¿¡æ¯

## å¿«é€Ÿå¼€å§‹

### 1. éƒ¨ç½² Keycloak
\`\`\`bash
./scripts/init_keycloak.sh
\`\`\`

### 2. å¯åŠ¨æœåŠ¡
\`\`\`bash
./scripts/dev.sh
\`\`\`

### 3. è®¿é—®åº”ç”¨
- Web UI: http://localhost:9300
- Keycloak Admin: http://192.168.1.248:8080/admin
```

**Step 3: Commit**

```bash
git add docs/ARCHITECTURE.md README.md
git commit -m "docs: add architecture documentation and update README"
```

---

## å®æ–½å®Œæˆæ€»ç»“

å®æ–½å®Œæˆåï¼Œç³»ç»Ÿå°†å…·å¤‡ï¼š

1. **Keycloak OIDC ç»Ÿä¸€è®¤è¯**
   - JWT Token éªŒè¯
   - SSO æ”¯æŒ
   - å¤šç³»ç»Ÿé›†æˆèƒ½åŠ›

2. **Token-aware ä¸‰çº§ä¸Šä¸‹æ–‡ç®¡ç†**
   - å·¥ä½œè®°å¿†(2K tokens)
   - çŸ­æœŸæ‘˜è¦(500 tokens)
   - é•¿æœŸè®°å¿†(1K tokens)
   - èŠ‚çœ 40-60% Token æˆæœ¬

3. **ä¸‰å±‚è®°å¿†æ¶æ„**
   - ç”¨æˆ·ç”»åƒå±‚(Redis)
   - å®ä½“è®°å¿†å±‚(è§„åˆ™+LLM)
   - è¯­ä¹‰è®°å¿†å±‚(Milvus)
   - å»é‡ + æ—¶é—´è¡°å‡

4. **æ™ºèƒ½æ‘˜è¦ç”Ÿæˆ**
   - ä¸»é¢˜åˆ‡æ¢æ£€æµ‹
   - åˆ†æ®µæ‘˜è¦
   - å¼‚æ­¥ç”Ÿæˆ

5. **æ€§èƒ½ä¼˜åŒ–**
   - ä¸Šä¸‹æ–‡æ„å»º P95 < 100ms
   - è®°å¿†æ£€ç´¢ P95 < 200ms
